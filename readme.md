Deepseek-r1 聊天机器人
Deepseek-r1 聊天机器人是一个基于 Streamlit 和 LangChain 构建的交互式聊天机器人应用。该应用使用 Ollama 的 deepseek-r1:1.5b 模型，根据用户的输入以韩语生成回答。
特性
固定标题：通过自定义 CSS，在顶部显示固定标题（Deepseek-r1），确保应用名称始终可见。
自定义侧边栏：在侧边栏底部添加了设置（⚙️）、开发者信息（👨‍💻）和模型信息（📦）的图标，可以按需切换相关面板。
最小化 Streamlit 默认标题：调整 Streamlit 默认标题（右上角的部署和三个点的图标）的高度和内边距，防止自定义标题被遮挡。
交互式聊天机器人：接收用户消息，通过 Ollama LLM 实时生成回答，并通过会话状态管理对话历史。
安装与运行
系统要求
Python 3.7 及以上版本
Streamlit
langchain_community 包及其依赖项
Ollama 模型运行环境（例如：使用 ollama pull deepseek-r1 命令下载模型）
安装方法
创建虚拟环境后，安装所需的包。
bash复制
pip install streamlit langchain_community
将以下代码保存为项目目录中的 app.py 文件。
使用以下命令运行应用。
bash复制
streamlit run app.py
使用方法
应用启动时，顶部会固定显示 Deepseek-r1 标题。
左侧侧边栏底部有三个图标，可以切换以下三个面板：
⚙️ 设置：提供温度调节和“清除对话历史”功能。
👨‍💻 开发者信息：显示开发者姓名和联系方式。
📦 模型信息：查看正在使用的模型（例如：deepseek-r1:32b）的信息。
在中间的聊天输入框中输入消息，聊天机器人会调用 Ollama LLM 以韩语生成回答。
对话历史通过会话状态进行管理，需要时可以通过侧边栏的“清除对话历史”按钮进行初始化。
代码结构及说明
页面设置及会话状态初始化
使用 st.set_page_config 设置页面标题及布局。
利用会话状态管理对话历史、温度设置以及侧边栏面板（设置、开发者信息、模型信息）的显示状态。
自定义 CSS
调整 Streamlit 默认标题区域的高度和内边距，防止自定义标题被遮挡。
调整 .block-container 的 padding-top，使页面内容合理布局。
设置聊天消息的样式，以便清晰地显示用户和 AI 的回答。
固定标题
使用 <div> 标签在顶部显示固定标题（Deepseek-r1），并通过内联样式设置背景色（黑色）和文字颜色（白色）。
侧边栏面板
根据会话状态切换设置、开发者信息、模型信息面板的显示。
在侧边栏底部添加间隔（Spacer），使图标靠右对齐。
聊天机器人逻辑
通过 st.chat_input 接收用户输入并保存到会话状态。
get_llm() 函数创建 Ollama LLM 实例，并根据输入提示生成回答。
在回答生成过程中显示加载动画（Spinner），并在发生错误时提供适当的错误信息和指导。
问题解决及注意事项
标题被遮挡问题：
可以通过 CSS 调整默认 Streamlit 标题的高度和内边距来解决。如有需要，可进一步调整 header[data-testid="stHeader"] 的高度值。
Ollama 连接错误：
请检查 Ollama 模型是否正常运行以及网络连接是否正常。
清除对话历史：
可以使用侧边栏的“清除对话历史”按钮来初始化正在进行的对话。
